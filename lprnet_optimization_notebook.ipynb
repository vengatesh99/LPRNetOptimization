{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx onnxruntime onnxscript\n",
        "!pip install torch-tensorrt\n",
        "!pip install --pre -U -f https://mlc.ai/wheels mlc-ai-nightly-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh5Vp2qx8aAP",
        "outputId": "b87960f8-0458-46a0-c128-98bd082f7af0",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting onnxscript\n",
            "  Downloading onnxscript-0.1.0.dev20241208-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.25.5)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from onnxscript) (4.12.2)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.10/dist-packages (from onnxscript) (0.4.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxscript-0.1.0.dev20241208-py3-none-any.whl (725 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m725.8/725.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, humanfriendly, onnxscript, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnxruntime-1.20.1 onnxscript-0.1.0.dev20241208\n",
            "Collecting torch-tensorrt\n",
            "  Downloading torch_tensorrt-2.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch<2.6.0,>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (2.5.1+cu121)\n",
            "Collecting tensorrt-cu12==10.3.0 (from torch-tensorrt)\n",
            "  Downloading tensorrt-cu12-10.3.0.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt-cu12-bindings==10.3.0 (from torch-tensorrt)\n",
            "  Downloading tensorrt_cu12_bindings-10.3.0-cp310-none-manylinux_2_17_x86_64.whl.metadata (627 bytes)\n",
            "Collecting tensorrt-cu12-libs==10.3.0 (from torch-tensorrt)\n",
            "  Downloading tensorrt_cu12_libs-10.3.0.tar.gz (630 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging>=23 in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (1.26.4)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (4.12.2)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.10/dist-packages (from tensorrt-cu12-libs==10.3.0->torch-tensorrt) (12.6.77)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.6.0,>=2.5.0->torch-tensorrt) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.6.0,>=2.5.0->torch-tensorrt) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.6.0,>=2.5.0->torch-tensorrt) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.6.0,>=2.5.0->torch-tensorrt) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<2.6.0,>=2.5.0->torch-tensorrt) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<2.6.0,>=2.5.0->torch-tensorrt) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.6.0,>=2.5.0->torch-tensorrt) (3.0.2)\n",
            "Downloading torch_tensorrt-2.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_34_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorrt_cu12_bindings-10.3.0-cp310-none-manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: tensorrt-cu12, tensorrt-cu12-libs\n",
            "  Building wheel for tensorrt-cu12 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt-cu12: filename=tensorrt_cu12-10.3.0-py2.py3-none-any.whl size=17553 sha256=cd956e7319e27c6a7e89302b84d0282452baf48e5a2e1ba7ccc7798d0d3fee6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/31/c2/a3ecb74def7087b76ef2a701e6823f03e40ab43348c668a571\n",
            "  Building wheel for tensorrt-cu12-libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt-cu12-libs: filename=tensorrt_cu12_libs-10.3.0-py2.py3-none-manylinux_2_17_x86_64.whl size=2037510258 sha256=736cb205d2d4ece7584f3b35e2495754864161895e9cbe3ff7d46b58c9680311\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/92/cb/f1923881cec4f328f262c0a68ec6ef5ac7685ed1187450cf8d\n",
            "Successfully built tensorrt-cu12 tensorrt-cu12-libs\n",
            "Installing collected packages: tensorrt-cu12-bindings, tensorrt-cu12-libs, tensorrt-cu12, torch-tensorrt\n",
            "Successfully installed tensorrt-cu12-10.3.0 tensorrt-cu12-bindings-10.3.0 tensorrt-cu12-libs-10.3.0 torch-tensorrt-2.5.0\n",
            "Looking in links: https://mlc.ai/wheels\n",
            "Collecting mlc-ai-nightly-cpu\n",
            "  Downloading https://github.com/mlc-ai/package/releases/download/v0.9.dev0/mlc_ai_nightly_cpu-0.18.dev249-cp310-cp310-manylinux_2_28_x86_64.whl (185.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.9/185.9 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly-cpu) (24.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly-cpu) (3.1.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly-cpu) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly-cpu) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly-cpu) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly-cpu) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly-cpu) (1.13.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly-cpu) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from mlc-ai-nightly-cpu) (4.12.2)\n",
            "Installing collected packages: mlc-ai-nightly-cpu\n",
            "Successfully installed mlc-ai-nightly-cpu-0.18.dev249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(\"cuda\")"
      ],
      "metadata": {
        "id": "AXS87QebzwsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qAjVztiq7m0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0284680f-0e93-43cb-f6b1-b1ed54d693e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torch_tensorrt.dynamo.conversion.aten_ops_converters:Unable to import quantization op. Please install modelopt library (https://github.com/NVIDIA/TensorRT-Model-Optimizer?tab=readme-ov-file#installation) to add support for compiling quantized models\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import *\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "# import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import *\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "if torch.cuda.is_available():\n",
        "    import torch_tensorrt\n",
        "import time\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import torch.nn.utils.prune as prune\n",
        "import copy\n",
        "import math\n",
        "from typing import List\n",
        "import tvm\n",
        "from tvm import relax as R\n",
        "from tvm import te\n",
        "from tvm import relay\n",
        "\n",
        "from tvm import autotvm\n",
        "from tvm.autotvm.tuner import XGBTuner\n",
        "import tvm.auto_scheduler as auto_scheduler\n",
        "from tvm.contrib import graph_executor\n",
        "\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "05zsnRFh7lYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tvm.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEt4mK48BgnZ",
        "outputId": "ad7c6235-4870-472e-b425-25a5cc292ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.19.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEGpvL8prTLV"
      },
      "outputs": [],
      "source": [
        "class small_basic_block(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super(small_basic_block, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(ch_in, ch_out // 4, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(3, 1), padding=(1, 0)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(1, 3), padding=(0, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(ch_out // 4, ch_out, kernel_size=1),\n",
        "        )\n",
        "        # self.conv1 = nn.Conv2d(ch_in, ch_out // 4, kernel_size=1)\n",
        "        # self.conv2 = nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(3, 1), padding=(1, 0))\n",
        "        # self.conv3 = nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(1, 3), padding=(0, 1))\n",
        "        # self.conv4 = nn.Conv2d(ch_out // 4, ch_out, kernel_size=1)\n",
        "        # self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "        # x = self.conv1(x)\n",
        "        # print(x.shape)\n",
        "        # x = self.relu(x)\n",
        "        # x = self.conv2(x)\n",
        "        # print(x.shape)\n",
        "        # x = self.relu(x)\n",
        "        # x = self.conv3(x)\n",
        "        # print(x.shape)\n",
        "        # x = self.relu(x)\n",
        "        # x = self.conv4(x)\n",
        "        return x\n",
        "\n",
        "class LPRNet(nn.Module):\n",
        "    def __init__(self, lpr_max_len, phase, class_num, dropout_rate):\n",
        "        super(LPRNet, self).__init__()\n",
        "        self.phase = phase\n",
        "        self.lpr_max_len = lpr_max_len\n",
        "        self.class_num = class_num\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1), # 0\n",
        "            nn.BatchNorm2d(num_features=64),\n",
        "            nn.ReLU(),  # 2\n",
        "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 1, 1)),\n",
        "            small_basic_block(ch_in=64, ch_out=128),    # *** 4 ***\n",
        "            nn.BatchNorm2d(num_features=128),\n",
        "            nn.ReLU(),  # 6\n",
        "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(2, 1, 2)),\n",
        "            small_basic_block(ch_in=64, ch_out=256),   # 8\n",
        "            nn.BatchNorm2d(num_features=256),\n",
        "            nn.ReLU(),  # 10\n",
        "            small_basic_block(ch_in=256, ch_out=256),   # *** 11 ***\n",
        "            nn.BatchNorm2d(num_features=256),   # 12\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(4, 1, 2)),  # 14\n",
        "            nn.Dropout(float(dropout_rate)),\n",
        "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=(1, 4), stride=1),  # 16\n",
        "            nn.BatchNorm2d(num_features=256),\n",
        "            nn.ReLU(),  # 18\n",
        "            nn.Dropout(float(dropout_rate)),\n",
        "            nn.Conv2d(in_channels=256, out_channels=class_num, kernel_size=(13, 1), stride=1), # 20\n",
        "            nn.BatchNorm2d(num_features=class_num),\n",
        "            nn.ReLU(),  # *** 22 ***\n",
        "        )\n",
        "        self.avg1 = nn.AvgPool2d(kernel_size=5, stride=5)\n",
        "        self.avg2 = nn.AvgPool2d(kernel_size=(4, 10), stride=(4, 2))\n",
        "        self.container = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=448+self.class_num, out_channels=self.class_num, kernel_size=(1, 1), stride=(1, 1)),\n",
        "            # nn.BatchNorm2d(num_features=self.class_num),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Conv2d(in_channels=self.class_num, out_channels=self.lpr_max_len+1, kernel_size=3, stride=2),\n",
        "            # nn.ReLU(),\n",
        "        )\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        keep_features = list()\n",
        "        x = self.quant(x)\n",
        "        for i, layer in enumerate(self.backbone.children()):\n",
        "            if i in [3, 7, 14]:\n",
        "                x = x.unsqueeze(0)\n",
        "            x = layer(x)\n",
        "            if i in [3, 7, 14]:\n",
        "                x = x.squeeze(0)\n",
        "            if i in [2, 6, 13, 22]: # [2, 4, 8, 11, 22]\n",
        "                keep_features.append(self.dequant(x))\n",
        "\n",
        "        global_context = list()\n",
        "        for i, f in enumerate(keep_features):\n",
        "            if i in [0, 1]:\n",
        "                f = self.avg1(f)\n",
        "            if i in [2]:\n",
        "                f = self.avg2(f)\n",
        "            f_pow = torch.pow(f, 2)\n",
        "            f_mean = torch.mean(f_pow)\n",
        "            f = torch.div(f, f_mean)\n",
        "            global_context.append(f)\n",
        "        x = self.dequant(x)\n",
        "        x = torch.cat(global_context, 1)\n",
        "        x = self.container(x)\n",
        "        logits = torch.mean(x, dim=2)\n",
        "\n",
        "        return logits\n",
        "\n",
        "def build_lprnet(lpr_max_len=8, phase=False, class_num=66, dropout_rate=0.5):\n",
        "\n",
        "    Net = LPRNet(lpr_max_len, phase, class_num, dropout_rate)\n",
        "\n",
        "    if phase == \"train\":\n",
        "        return Net.train()\n",
        "    else:\n",
        "        return Net.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJRXdE48tT9a"
      },
      "outputs": [],
      "source": [
        "CHARS = ['京', '沪', '津', '渝', '冀', '晋', '蒙', '辽', '吉', '黑',\n",
        "         '苏', '浙', '皖', '闽', '赣', '鲁', '豫', '鄂', '湘', '粤',\n",
        "         '桂', '琼', '川', '贵', '云', '藏', '陕', '甘', '青', '宁',\n",
        "         '新',\n",
        "         '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "         'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K',\n",
        "         'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V',\n",
        "         'W', 'X', 'Y', 'Z', 'I', 'O', '-'\n",
        "         ]\n",
        "\n",
        "CHARS_DICT = {char:i for i, char in enumerate(CHARS)}\n",
        "\n",
        "class LPRDataLoader(Dataset):\n",
        "    def __init__(self, img_dir, imgSize, lpr_max_len, PreprocFun=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.img_paths = []\n",
        "        for i in range(len(img_dir)):\n",
        "            self.img_paths += [el for el in paths.list_images(img_dir[i])]\n",
        "        random.shuffle(self.img_paths)\n",
        "        self.img_size = imgSize\n",
        "        self.lpr_max_len = lpr_max_len\n",
        "        if PreprocFun is not None:\n",
        "            self.PreprocFun = PreprocFun\n",
        "        else:\n",
        "            self.PreprocFun = self.transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.img_paths[index]\n",
        "        Image = cv2.imread(filename)\n",
        "        height, width, _ = Image.shape\n",
        "        if height != self.img_size[1] or width != self.img_size[0]:\n",
        "            Image = cv2.resize(Image, self.img_size)\n",
        "        Image = self.PreprocFun(Image)\n",
        "\n",
        "        basename = os.path.basename(filename)\n",
        "        imgname, suffix = os.path.splitext(basename)\n",
        "        imgname = imgname.split(\"-\")[0].split(\"_\")[0]\n",
        "        label = list()\n",
        "        for c in imgname:\n",
        "            # one_hot_base = np.zeros(len(CHARS))\n",
        "            # one_hot_base[CHARS_DICT[c]] = 1\n",
        "            label.append(CHARS_DICT[c])\n",
        "\n",
        "        if len(label) == 8:\n",
        "            if self.check(label) == False:\n",
        "                print(imgname)\n",
        "                assert 0, \"Error label ^~^!!!\"\n",
        "\n",
        "        return Image, label, len(label)\n",
        "\n",
        "    def transform(self, img):\n",
        "        img = img.astype('float32')\n",
        "        img -= 127.5\n",
        "        img *= 0.0078125\n",
        "        img = np.transpose(img, (2, 0, 1))\n",
        "\n",
        "        return img\n",
        "\n",
        "    def check(self, label):\n",
        "        if label[2] != CHARS_DICT['D'] and label[2] != CHARS_DICT['F'] \\\n",
        "                and label[-1] != CHARS_DICT['D'] and label[-1] != CHARS_DICT['F']:\n",
        "            print(\"Error label, Please check!\")\n",
        "            return False\n",
        "        else:\n",
        "            return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G38IpfQFvZMA"
      },
      "outputs": [],
      "source": [
        "def get_args():\n",
        "    class Args:\n",
        "      pass\n",
        "    args = Args()\n",
        "    args.cuda = False\n",
        "    args.num_workers = 8\n",
        "    args.test_batch_size = 100\n",
        "    args.show = False\n",
        "    args.dropout_rate = 0\n",
        "    args.img_size = [94, 24]\n",
        "    args.test_img_dirs = \"drive/MyDrive/LPRNet_Pytorch/data/test\"\n",
        "    args.lpr_max_len = 8\n",
        "    args.phase_train = False\n",
        "    args.pretrained_model = \"drive/MyDrive/LPRNet_Pytorch/weights/Final_LPRNet_model.pth\"\n",
        "    args.jit_autotune = False\n",
        "    return args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Gr76LVetqC5"
      },
      "outputs": [],
      "source": [
        "def get_model_size_onnx(model):\n",
        "    onnx_pgm = torch.onnx.dynamo_export(model, torch.randn(1, 3, 24, 94))\n",
        "    onnx_pgm.save(\"model.onnx\")\n",
        "    model_size = os.path.getsize(\"model.onnx\")\n",
        "    return model_size / (1024 * 1024)\n",
        "\n",
        "def get_model_size(model: nn.Module, data_width=32, count_nonzero_only=False) -> int:\n",
        "    \"\"\"\n",
        "    calculate the model size in bits\n",
        "    :param data_width: #bits per element\n",
        "    :param count_nonzero_only: only count nonzero weights\n",
        "    \"\"\"\n",
        "    return get_num_parameters(model, count_nonzero_only) * data_width\n",
        "\n",
        "def get_num_parameters(model: nn.Module, count_nonzero_only=False) -> int:\n",
        "    \"\"\"\n",
        "    calculate the total number of parameters of model\n",
        "    :param count_nonzero_only: only count nonzero weights\n",
        "    \"\"\"\n",
        "    num_counted_elements = 0\n",
        "    for param in model.parameters():\n",
        "        if count_nonzero_only:\n",
        "            num_counted_elements += param.count_nonzero()\n",
        "        else:\n",
        "            num_counted_elements += param.numel()\n",
        "    return num_counted_elements\n",
        "\n",
        "def collate_fn(batch):\n",
        "    imgs = []\n",
        "    labels = []\n",
        "    lengths = []\n",
        "    for _, sample in enumerate(batch):\n",
        "        img, label, length = sample\n",
        "        imgs.append(torch.from_numpy(img))\n",
        "        labels.extend(label)\n",
        "        lengths.append(length)\n",
        "    labels = np.asarray(labels).flatten().astype(np.float32)\n",
        "\n",
        "    return (torch.stack(imgs, 0), torch.from_numpy(labels), lengths)\n",
        "\n",
        "def test(normal = True, quantize_flag = False, weight_quantize_flag=False, fuse_flag=False,\n",
        "         sparsity_flag=False, prune_flag=False, jit_compile=False, torch_compile=False,\n",
        "         tensorrt_compile=False, jit_autotune = False, quant_tensorrt_compile_flag=False):\n",
        "    args = get_args()\n",
        "    # device  = torch.device(\"cpu\")\n",
        "    lprnet = build_lprnet(lpr_max_len=args.lpr_max_len, phase=args.phase_train, class_num=len(CHARS), dropout_rate=args.dropout_rate)\n",
        "    # args.jit_autotune = jit_autotune\n",
        "\n",
        "    # if args.jit_autotune:\n",
        "    #   device = torch.device(\"cuda:0\")\n",
        "    # lprnet.to(device)\n",
        "    device = torch.device(\"cuda:0\" if args.cuda else \"cpu\")\n",
        "    lprnet.to(device)\n",
        "    print(\"Successful to build network!\")\n",
        "\n",
        "    # load pretrained model\n",
        "    if args.pretrained_model:\n",
        "        lprnet.load_state_dict(torch.load(args.pretrained_model, map_location=device))\n",
        "        print(\"load pretrained model successful!\")\n",
        "    else:\n",
        "        print(\"[Error] Can't found pretrained mode, please check!\")\n",
        "        return False\n",
        "\n",
        "    test_img_dirs = os.path.expanduser(args.test_img_dirs)\n",
        "    test_dataset = LPRDataLoader(test_img_dirs.split(','), args.img_size, args.lpr_max_len)\n",
        "    if fuse_flag:\n",
        "        lprnet = fuse_lprnet(lprnet)\n",
        "        print(\"Fused Model\")\n",
        "        Greedy_Decode_Eval(lprnet, test_dataset, args)\n",
        "    if quantize_flag:\n",
        "        qconfig = torch.quantization.get_default_qconfig('x86')\n",
        "        lprnet.qconfig = qconfig\n",
        "        lprnet.container.qconfig = None\n",
        "        lprnet = torch.quantization.prepare(lprnet, inplace=True)\n",
        "        calibrate_dataset = Subset(test_dataset, range(100))\n",
        "        print(\"Running calibration on the lprtnet Model\")\n",
        "        Greedy_Decode_Eval(lprnet, calibrate_dataset, args)\n",
        "        lprnet = torch.quantization.convert(lprnet, inplace=True)\n",
        "        print(\"Quantized Model\")\n",
        "        Greedy_Decode_Eval(lprnet, test_dataset, args)\n",
        "    if weight_quantize_flag:\n",
        "        quantizer = WeightQuantizer(bits=8)\n",
        "        quantized_model = quantizer.quantize_model(lprnet)\n",
        "        print(\"Weight Quantized Model\")\n",
        "        Greedy_Decode_Eval(quantized_model, test_dataset, args)\n",
        "\n",
        "    if sparsity_flag:\n",
        "        sz = get_model_size(lprnet) / (1024 * 1024 * 8)\n",
        "        print(\"Model Size: {} MB\".format(sz))\n",
        "        apply_pruning(lprnet)\n",
        "        # num_non_pruned_params = get_num_parameters(lprnet, count_nonzero_only=False)\n",
        "        # # sparsity_1_4(lprnet)\n",
        "        # sparsity_1_4(lprnet)\n",
        "        # num_pruned_params = get_num_parameters(lprnet, count_nonzero_only=True)\n",
        "        # print(f\"Total Number of parameters: {num_non_pruned_params}\")\n",
        "        # print(f\"Number of pruned parameters: {num_pruned_params}\")\n",
        "        # print(f\"Size reduced by {100 * (1 - (num_pruned_params / num_non_pruned_params)):.2f}%\")\n",
        "        Greedy_Decode_Eval(lprnet, test_dataset, args)\n",
        "    if prune_flag:\n",
        "        num_non_pruned_params = get_num_parameters(lprnet, count_nonzero_only=False)\n",
        "        pruner = ChannelPruner(lprnet.backbone, 0.5)\n",
        "        pruner.apply(lprnet.backbone)\n",
        "        num_pruned_params = get_num_parameters(lprnet, count_nonzero_only=True)\n",
        "        print(\"Pruned Model\")\n",
        "        print(f\"Number of non-pruned parameters: {num_non_pruned_params}\")\n",
        "        print(f\"Number of pruned parameters: {num_pruned_params}\")\n",
        "        print(f\"Size reduced by {100 * (1 - (num_pruned_params / num_non_pruned_params)):.2f}%\")\n",
        "        Greedy_Decode_Eval(lprnet, test_dataset, args)\n",
        "        # return\n",
        "    if jit_compile:\n",
        "        lprnet = torch.jit.optimize_for_inference(torch.jit.script(lprnet.eval()))\n",
        "        print(\"JIT Model\")\n",
        "        Greedy_Decode_Eval(lprnet, test_dataset, args)\n",
        "    if torch_compile:\n",
        "        lprnet = torch.compile(lprnet)\n",
        "        print(\"Torch Model\")\n",
        "        Greedy_Decode_Eval(lprnet, test_dataset, args)\n",
        "    if tensorrt_compile:\n",
        "        args.cuda = True\n",
        "        # inputs = torch_tensorrt.Input(min_shape=[1, 3, *args.img_size[::-1]],\n",
        "        #                       opt_shape=[args.test_batch_size, 3, *args.img_size[::-1]],\n",
        "        #                       max_shape=[int(1.5 * args.test_batch_size), 3, *args.img_size[::-1]],\n",
        "        #                       dtype=torch.float32)\n",
        "        # lprnet = torch_tensorrt.compile(lprnet.cuda(), ir=\"dynamo\", inputs=inputs, assume_dynamic_shape_support=True)\n",
        "        torch.compile(lprnet.cuda(), backend=\"torch_tensorrt\", dynamic=False)\n",
        "        print(\"TensorRT Model\")\n",
        "        Greedy_Decode_Eval(lprnet, test_dataset, args)\n",
        "    if quant_tensorrt_compile_flag:\n",
        "        # args.cuda = True\n",
        "        quantizer = WeightQuantizer(bits=8)\n",
        "        quantized_model = quantizer.quantize_model(lprnet)\n",
        "        print(\"Weight Quantized Model\")\n",
        "        args.cuda = True\n",
        "        torch.compile(lprnet.cuda(), backend=\"torch_tensorrt\", dynamic=False)\n",
        "        print(\"Quant TensorRT Model\")\n",
        "        Greedy_Decode_Eval(lprnet, test_dataset, args)\n",
        "    if jit_autotune:\n",
        "        args.jit_autotune = True\n",
        "        print(\"Relay Autotune Model\")\n",
        "        Greedy_Decode_Eval(lprnet, test_dataset, args)\n",
        "    if normal:\n",
        "        Greedy_Decode_Eval(lprnet, test_dataset, args)\n",
        "    # try:\n",
        "    #     Greedy_Decode_Eval(lprnet, test_dataset, args)\n",
        "    # finally:\n",
        "    #     # cv2.destroyAllWindows()\n",
        "    #     pass\n",
        "\n",
        "    sz = get_model_size(lprnet, count_nonzero_only=True) / (1024 * 1024 * 8)\n",
        "    print(\"Model Size: {} MB\".format(sz))\n",
        "\n",
        "def Greedy_Decode_Eval(Net, datasets, args):\n",
        "    # TestNet = Net.eval()\n",
        "    epoch_size = len(datasets) // args.test_batch_size\n",
        "    batch_iterator = iter(DataLoader(datasets, args.test_batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn))\n",
        "    if args.jit_autotune:\n",
        "      module_optim = get_optimized_model(args.test_batch_size, Net)\n",
        "    Tp = 0\n",
        "    Tn_1 = 0\n",
        "    Tn_2 = 0\n",
        "    t1 = time.time()\n",
        "    for i in range(epoch_size):\n",
        "        # load train data\n",
        "        images, labels, lengths = next(batch_iterator)\n",
        "        start = 0\n",
        "        targets = []\n",
        "        for length in lengths:\n",
        "            label = labels[start:start+length]\n",
        "            targets.append(label)\n",
        "            start += length\n",
        "        targets = np.array([el.numpy() for el in targets])\n",
        "        imgs = images.numpy().copy()\n",
        "\n",
        "        if args.cuda:\n",
        "            images = Variable(images.cuda())\n",
        "        else:\n",
        "            images = Variable(images)\n",
        "\n",
        "        # forward\n",
        "        if args.jit_autotune:\n",
        "          module_optim.set_input(\"data\", images)\n",
        "          module_optim.run()\n",
        "          output_shape = (args.test_batch_size, 68, 18)\n",
        "          prebs = module_optim.get_output(0, tvm.nd.empty(output_shape)).numpy()\n",
        "        else:\n",
        "          prebs = Net(images)\n",
        "          prebs = prebs.cpu().detach().numpy()\n",
        "\n",
        "        # greedy decode\n",
        "\n",
        "        preb_labels = list()\n",
        "        for i in range(prebs.shape[0]):\n",
        "            preb = prebs[i, :, :]\n",
        "            preb_label = list()\n",
        "            for j in range(preb.shape[1]):\n",
        "                preb_label.append(np.argmax(preb[:, j], axis=0))\n",
        "            no_repeat_blank_label = list()\n",
        "            pre_c = preb_label[0]\n",
        "            if pre_c != len(CHARS) - 1:\n",
        "                no_repeat_blank_label.append(pre_c)\n",
        "            for c in preb_label: # dropout repeate label and blank label\n",
        "                if (pre_c == c) or (c == len(CHARS) - 1):\n",
        "                    if c == len(CHARS) - 1:\n",
        "                        pre_c = c\n",
        "                    continue\n",
        "                no_repeat_blank_label.append(c)\n",
        "                pre_c = c\n",
        "            preb_labels.append(no_repeat_blank_label)\n",
        "        for i, label in enumerate(preb_labels):\n",
        "            # show image and its predict label\n",
        "            if args.show:\n",
        "                show(imgs[i], label, targets[i])\n",
        "            if len(label) != len(targets[i]):\n",
        "                Tn_1 += 1\n",
        "                continue\n",
        "            if (np.asarray(targets[i]) == np.asarray(label)).all():\n",
        "                Tp += 1\n",
        "            else:\n",
        "                Tn_2 += 1\n",
        "        # for i, (pred_label, target) in enumerate(zip(preb_labels, targets)):\n",
        "        #         print(f\"\\nSample {i}:\")\n",
        "        #         print(f\"Predicted: {pred_label}\")\n",
        "        #         print(f\"Target: {target}\")\n",
        "\n",
        "        #         if len(pred_label) != len(target):\n",
        "        #             print(\"Length mismatch\")\n",
        "        #             continue\n",
        "        #         if (np.asarray(target) == np.asarray(pred_label)).all():\n",
        "        #             print(\"Correct prediction\")\n",
        "        #         else:\n",
        "        #             print(\"Wrong prediction\")\n",
        "\n",
        "    Acc = Tp * 1.0 / (Tp + Tn_1 + Tn_2)\n",
        "    print(\"[Info] Test Accuracy: {} [{}:{}:{}:{}]\".format(Acc, Tp, Tn_1, Tn_2, (Tp+Tn_1+Tn_2)))\n",
        "    t2 = time.time()\n",
        "    print(\"[Info] Test Speed: {}s 1/{}]\".format((t2 - t1) / len(datasets), len(datasets)))\n",
        "\n",
        "def show(img, label, target):\n",
        "    img = np.transpose(img, (1, 2, 0))\n",
        "    img *= 128.\n",
        "    img += 127.5\n",
        "    img = img.astype(np.uint8)\n",
        "\n",
        "    lb = \"\"\n",
        "    for i in label:\n",
        "        lb += CHARS[i]\n",
        "    tg = \"\"\n",
        "    for j in target.tolist():\n",
        "        tg += CHARS[int(j)]\n",
        "\n",
        "    flag = \"F\"\n",
        "    if lb == tg:\n",
        "        flag = \"T\"\n",
        "    # img = cv2.putText(img, lb, (0,16), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.6, (0, 0, 255), 1)\n",
        "    # img = cv2ImgAddText(img, lb, (0, 0))\n",
        "    # cv2.imshow(\"test\", img)\n",
        "    print(\"target: \", tg, \" ### {} ### \".format(flag), \"predict: \", lb)\n",
        "    # cv2.waitKey()\n",
        "    # cv2.destroyAllWindows()\n",
        "\n",
        "def cv2ImgAddText(img, text, pos, textColor=(255, 0, 0), textSize=12):\n",
        "    if (isinstance(img, np.ndarray)):  # detect opencv format or not\n",
        "        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    fontText = ImageFont.truetype(\"data/NotoSansCJK-Regular.ttc\", textSize, encoding=\"utf-8\")\n",
        "    draw.text(pos, text, textColor, font=fontText)\n",
        "\n",
        "    return cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Test Accuracy and execution without optimizations"
      ],
      "metadata": {
        "id": "tFRbNYdM2RBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7Wbs-Hq2vYS",
        "outputId": "546ca3a4-52cd-463c-e848-ab537ae9b32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful to build network!\n",
            "load pretrained model successful!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4bbca89c341d>:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lprnet.load_state_dict(torch.load(args.pretrained_model, map_location=device))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Test Accuracy: 0.899 [899:58:43:1000]\n",
            "[Info] Test Speed: 0.2635062732696533s 1/1000]\n",
            "Model Size: 1.7050743103027344 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fusing model"
      ],
      "metadata": {
        "id": "dCR3vO6BScqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fuse_small_basic_block(block):\n",
        "    # Fuse Conv2d + ReLU layers in the block\n",
        "    torch.quantization.fuse_modules(block.block, ['0', '1'], inplace=True)\n",
        "    torch.quantization.fuse_modules(block.block, ['2', '3'], inplace=True)\n",
        "    torch.quantization.fuse_modules(block.block, ['4', '5'], inplace=True)\n",
        "    return block\n",
        "\n",
        "def fuse_lprnet(model):\n",
        "    # Fuse the layers in the backbone sequentially\n",
        "    backbone = model.backbone\n",
        "    torch.quantization.fuse_modules(backbone, ['0', '1', '2'], inplace=True)\n",
        "    backbone[4] = fuse_small_basic_block(backbone[4])\n",
        "    backbone[8] = fuse_small_basic_block(backbone[8])\n",
        "    backbone[11] = fuse_small_basic_block(backbone[11])\n",
        "    torch.quantization.fuse_modules(backbone, ['16', '17', '18'], inplace=True)\n",
        "    torch.quantization.fuse_modules(backbone, ['20', '21', '22'], inplace=True)\n",
        "    return model"
      ],
      "metadata": {
        "id": "LpaWc6KsX3vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reporting Metrics after Fusing and Post Static Quantization"
      ],
      "metadata": {
        "id": "FFfOAE4g06Em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(False,True,True,False,False,False,False,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDwjrRY8yTKk",
        "outputId": "c34053b8-58be-4094-9ed9-dd94c063d7e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful to build network!\n",
            "load pretrained model successful!\n",
            "Fused Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4bbca89c341d>:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lprnet.load_state_dict(torch.load(args.pretrained_model, map_location=device))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Test Accuracy: 0.896 [896:63:41:1000]\n",
            "[Info] Test Speed: 0.13891670632362366s 1/1000]\n",
            "Running calibration on the lprtnet Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Test Accuracy: 0.88 [88:6:6:100]\n",
            "[Info] Test Speed: 0.16175062894821168s 1/100]\n",
            "Quantized Model\n",
            "[Info] Test Accuracy: 0.851 [851:99:50:1000]\n",
            "[Info] Test Speed: 0.02904822301864624s 1/1000]\n",
            "Model Size: 0.1389923095703125 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing 1:4 Sparsity based pruning"
      ],
      "metadata": {
        "id": "e6eKGO-MTfIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "class OneFourPruning(prune.BasePruningMethod):\n",
        "    \"\"\"\n",
        "    This class implements 1:4 pruning: in each group of 4 weights,\n",
        "    we keep the largest one and zero out the other three.\n",
        "    \"\"\"\n",
        "    PRUNING_TYPE = \"structured_1_4\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def compute_mask(self, tensor, default_mask):\n",
        "        # First, let's make sure our tensor can be divided into groups of 4\n",
        "        if tensor.numel() % 4 != 0:\n",
        "            raise ValueError(f\"Tensor has {tensor.numel()} elements which isn't divisible by 4\")\n",
        "\n",
        "        # Reshape the tensor into groups of 4\n",
        "        original_shape = tensor.shape\n",
        "        weights_grouped = tensor.view(-1, 4)\n",
        "\n",
        "        # Find absolute values to compare weight magnitudes\n",
        "        abs_weights = torch.abs(weights_grouped)\n",
        "\n",
        "        # For each group of 4, find the indices of the 3 smallest weights\n",
        "        # We'll keep the largest one and zero out these three\n",
        "        _, indices = torch.topk(abs_weights, k=1, dim=1, largest=False)\n",
        "\n",
        "        # Create a mask of ones (keep all weights initially)\n",
        "        mask = torch.ones_like(weights_grouped)\n",
        "\n",
        "        # Set the mask to zero for the 3 smallest weights in each group\n",
        "        mask.scatter_(dim=1, index=indices, value=0)\n",
        "\n",
        "        # Reshape the mask back to the original tensor shape\n",
        "        return mask.view_as(tensor) * default_mask\n",
        "\n",
        "def apply_pruning(model):\n",
        "    \"\"\"\n",
        "    Applies 1:4 pruning to all Conv2d and Linear layers in the model.\n",
        "    The pruning is made permanent so it persists during training.\n",
        "    \"\"\"\n",
        "    print(\"Starting pruning process...\")\n",
        "\n",
        "    # Let's keep track of how many parameters we're pruning\n",
        "    total_params = 0\n",
        "    pruned_params = 0\n",
        "\n",
        "    for name, module in model.named_modules():\n",
        "        # We'll prune both Conv2d and Linear layers\n",
        "        if isinstance(module, (nn.Conv2d)) and not name.startswith('container'):\n",
        "            # Count parameters before pruning\n",
        "            total_params += module.weight.numel()\n",
        "\n",
        "            # Apply our 1:4 pruning\n",
        "            prune.custom_from_mask(\n",
        "                module,\n",
        "                name='weight',\n",
        "                mask=OneFourPruning.apply(module, 'weight').compute_mask(\n",
        "                    module.weight,\n",
        "                    torch.ones_like(module.weight)\n",
        "                )\n",
        "            )\n",
        "            # OneFourPruning.apply(module, 'weight')\n",
        "\n",
        "            # Count non-zero parameters after pruning\n",
        "            nonzero_params = torch.count_nonzero(module.weight).item()\n",
        "            pruned_params += module.weight.numel() - nonzero_params\n",
        "\n",
        "            # Make the pruning permanent\n",
        "            # This ensures the pruning mask is applied to the weights\n",
        "            # and the pruning persists during training\n",
        "            prune.remove(module, 'weight')\n",
        "\n",
        "            print(f\"Layer {name}:\")\n",
        "            print(f\"  Total parameters: {module.weight.numel()}\")\n",
        "            print(f\"  Non-zero parameters: {nonzero_params}\")\n",
        "            print(f\"  Sparsity: {100 * (1 - nonzero_params/module.weight.numel()):.2f}%\")\n",
        "\n",
        "    print(\"\\nOverall pruning results:\")\n",
        "    print(f\"Total parameters: {total_params}\")\n",
        "    print(f\"Pruned parameters: {pruned_params}\")\n",
        "    print(f\"Overall sparsity: {100 * pruned_params/total_params:.2f}%\")"
      ],
      "metadata": {
        "id": "4ScdzPcaTpNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test(False,False,False,True,False,False,False,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsMEicCJ23X9",
        "outputId": "44734cd2-1ece-4e27-8d2c-329772ed79e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful to build network!\n",
            "load pretrained model successful!\n",
            "Model Size: 1.705078125 MB\n",
            "Starting pruning process...\n",
            "Layer backbone.0:\n",
            "  Total parameters: 1728\n",
            "  Non-zero parameters: 1296\n",
            "  Sparsity: 25.00%\n",
            "Layer backbone.4.block.0:\n",
            "  Total parameters: 2048\n",
            "  Non-zero parameters: 1536\n",
            "  Sparsity: 25.00%\n",
            "Layer backbone.4.block.2:\n",
            "  Total parameters: 3072\n",
            "  Non-zero parameters: 2304\n",
            "  Sparsity: 25.00%\n",
            "Layer backbone.4.block.4:\n",
            "  Total parameters: 3072\n",
            "  Non-zero parameters: 2304\n",
            "  Sparsity: 25.00%\n",
            "Layer backbone.4.block.6:\n",
            "  Total parameters: 4096\n",
            "  Non-zero parameters: 3072\n",
            "  Sparsity: 25.00%\n",
            "Layer backbone.8.block.0:\n",
            "  Total parameters: 4096\n",
            "  Non-zero parameters: 3072\n",
            "  Sparsity: 25.00%\n",
            "Layer backbone.8.block.2:\n",
            "  Total parameters: 12288\n",
            "  Non-zero parameters: 9216\n",
            "  Sparsity: 25.00%\n",
            "Layer backbone.8.block.4:\n",
            "  Total parameters: 12288\n",
            "  Non-zero parameters: 9216\n",
            "  Sparsity: 25.00%\n",
            "Layer backbone.8.block.6:\n",
            "  Total parameters: 16384\n",
            "  Non-zero parameters: 12288\n",
            "  Sparsity: 25.00%\n",
            "Layer backbone.11.block.0:\n",
            "  Total parameters: 16384\n",
            "  Non-zero parameters: 12288\n",
            "  Sparsity: 25.00%\n",
            "Layer backbone.11.block.2:\n",
            "  Total parameters: 12288\n",
            "  Non-zero parameters: 9216\n",
            "  Sparsity: 25.00%\n",
            "Layer backbone.11.block.4:\n",
            "  Total parameters: 12288\n",
            "  Non-zero parameters: 9216\n",
            "  Sparsity: 25.00%\n",
            "Layer backbone.11.block.6:\n",
            "  Total parameters: 16384\n",
            "  Non-zero parameters: 12288\n",
            "  Sparsity: 25.00%\n",
            "Layer backbone.16:\n",
            "  Total parameters: 65536\n",
            "  Non-zero parameters: 49152\n",
            "  Sparsity: 25.00%\n",
            "Layer backbone.20:\n",
            "  Total parameters: 226304\n",
            "  Non-zero parameters: 169728\n",
            "  Sparsity: 25.00%\n",
            "\n",
            "Overall pruning results:\n",
            "Total parameters: 408256\n",
            "Pruned parameters: 102064\n",
            "Overall sparsity: 25.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4bbca89c341d>:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lprnet.load_state_dict(torch.load(args.pretrained_model, map_location=device))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Test Accuracy: 0.686 [686:188:126:1000]\n",
            "[Info] Test Speed: 0.24449558472633362s 1/1000]\n",
            "Model Size: 1.31573486328125 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Channel Pruning"
      ],
      "metadata": {
        "id": "1hNxPhWYWKqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def channel_prune(tensor: torch.Tensor, sparsity: float) -> torch.Tensor:\n",
        "\n",
        "    orig_size = tensor.shape\n",
        "    tensor = tensor.view(-1)\n",
        "    num_channels = tensor.shape[0]\n",
        "    num_pruned_channels = round(num_channels * sparsity)\n",
        "\n",
        "    channel_norms = tensor.abs()#.sum(dim=(1, 2, 3))  # Calculate L1 norm for each channel\n",
        "    threshold = channel_norms.kthvalue(num_pruned_channels).values\n",
        "    mask = torch.gt(channel_norms, threshold).float()\n",
        "    mask = mask.view(orig_size)\n",
        "    # mask = mask.unsqueeze(1).unsqueeze(2).unsqueeze(3).expand_as(tensor)\n",
        "    return mask\n",
        "\n",
        "\n",
        "class ChannelPruner:\n",
        "    def __init__(self, model, sparsity_dict):\n",
        "        self.masks = ChannelPruner.prune(model, sparsity_dict)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def apply(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if name in self.masks:\n",
        "                param *= self.masks[name]\n",
        "\n",
        "    @staticmethod\n",
        "    @torch.no_grad()\n",
        "    def prune(model, sparsity_dict):\n",
        "        masks = dict()\n",
        "        for name, param in model.named_parameters():\n",
        "            if \"weight\" in name and len(param.shape) == 4:  # Channel pruning for Conv layers\n",
        "                if isinstance(sparsity_dict, dict):\n",
        "                    masks[name] = channel_prune(param, sparsity_dict[name])\n",
        "                else:\n",
        "                    assert (sparsity_dict < 1 and sparsity_dict >= 0)\n",
        "                    if sparsity_dict > 0:\n",
        "                        masks[name] = channel_prune(param, sparsity_dict)\n",
        "        return masks\n"
      ],
      "metadata": {
        "id": "O_-f63PhIykc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(normal = False, prune_flag=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F--BkwI-WJ5u",
        "outputId": "66d954d1-cf3a-4087-fadd-22c2290cfc9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful to build network!\n",
            "load pretrained model successful!\n",
            "Pruned Model\n",
            "Number of non-pruned parameters: 446976\n",
            "Number of pruned parameters: 242845\n",
            "Size reduced by 45.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-4bbca89c341d>:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lprnet.load_state_dict(torch.load(args.pretrained_model, map_location=device))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Test Accuracy: 0.823 [823:101:76:1000]\n",
            "[Info] Test Speed: 0.192450138092041s 1/1000]\n",
            "Model Size: 0.9263801574707031 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weight Quantization"
      ],
      "metadata": {
        "id": "QSjBadHKerlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class WeightQuantizer:\n",
        "    def __init__(self, bits=8):\n",
        "        self.bits = bits\n",
        "        self.qmin = -(2 ** (bits - 1))\n",
        "        self.qmax = 2 ** (bits - 1) - 1\n",
        "\n",
        "    def quantize_tensor(self, tensor):\n",
        "        # Calculate scale factor\n",
        "        scale = (tensor.max() - tensor.min()) / (self.qmax - self.qmin)\n",
        "\n",
        "        # Zero point computation\n",
        "        zero_point = self.qmin - torch.round(tensor.min() / scale)\n",
        "\n",
        "        # Clip values\n",
        "        q_tensor = torch.clip(torch.round(tensor / scale + zero_point),\n",
        "                            self.qmin, self.qmax)\n",
        "\n",
        "        # Dequantize for forward pass\n",
        "        return (q_tensor - zero_point) * scale\n",
        "\n",
        "    def quantize_model(self, model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                param.data = self.quantize_tensor(param.data)\n",
        "        return model\n",
        "\n",
        "def test_quantization():\n",
        "    # Create sample model\n",
        "    lprnet = build_lprnet(lpr_max_len=8, phase=False, class_num=68, dropout_rate=0.5)\n",
        "\n",
        "    # Initialize quantizer\n",
        "    quantizer = WeightQuantizer(bits=8)\n",
        "\n",
        "    # Quantize weights\n",
        "    quantizer = WeightQuantizer(bits=8)\n",
        "    quantized_model = quantizer.quantize_model(model)\n",
        "\n",
        "    return quantized_model"
      ],
      "metadata": {
        "id": "KJSKLeloev5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(normal=False, weight_quantize_flag=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWxYRpJxuVsF",
        "outputId": "d0f47908-5fa9-4c5a-9733-e5bf3c1fe338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful to build network!\n",
            "load pretrained model successful!\n",
            "Weight Quantized Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-52679b166827>:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lprnet.load_state_dict(torch.load(args.pretrained_model, map_location=device))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Test Accuracy: 0.899 [899:65:36:1000]\n",
            "[Info] Test Speed: 0.04648841619491577s 1/1000]\n",
            "Model Size: 0.2580413818359375 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLC Optimization"
      ],
      "metadata": {
        "id": "UllFAI9m1D0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autotune using relay and JIT"
      ],
      "metadata": {
        "id": "ag2Qw02VKc_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"llvm\""
      ],
      "metadata": {
        "id": "1rDEYxciKHbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimized_model(test_batch_size, model):\n",
        "  # model = build_lprnet(lpr_max_len=args.lpr_max_len, phase=args.phase_train, class_num=len(CHARS), dropout_rate=args.dropout_rate)\n",
        "  input_name = \"data\"\n",
        "  input_data = torch.randn(test_batch_size, 3, 24, 94)\n",
        "  scripted_model = torch.jit.trace(model, input_data).eval()\n",
        "  shape_list = [(input_name, input_data.shape)]\n",
        "  mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)\n",
        "  with tvm.transform.PassContext(opt_level=3):\n",
        "    lib = relay.build(mod, target=target, params=params)\n",
        "  dev = tvm.device(str(target), 0)\n",
        "  module = graph_executor.GraphModule(lib[\"default\"](dev))\n",
        "\n",
        "  number = 10\n",
        "  repeat = 1\n",
        "  min_repeat_ms = 0  # since we're tuning on a CPU, can be set to 0\n",
        "  timeout = 10  # in seconds\n",
        "\n",
        "  # create a TVM runner\n",
        "  runner = autotvm.LocalRunner(\n",
        "      number=number,\n",
        "      repeat=repeat,\n",
        "      timeout=timeout,\n",
        "      min_repeat_ms=min_repeat_ms,\n",
        "      enable_cpu_cache_flush=True,\n",
        "  )\n",
        "\n",
        "  tuning_option = {\n",
        "      \"tuner\": \"xgb\",\n",
        "      \"trials\": 20,\n",
        "      \"early_stopping\": 100,\n",
        "      \"measure_option\": autotvm.measure_option(\n",
        "          builder=autotvm.LocalBuilder(build_func=\"default\"), runner=runner\n",
        "      ),\n",
        "      \"tuning_records\": \"autotuning.json\",\n",
        "  }\n",
        "  tasks = autotvm.task.extract_from_program(mod[\"main\"], target=target, params=params)\n",
        "\n",
        "  for i, task in enumerate(tasks):\n",
        "      prefix = \"[Task %2d/%2d] \" % (i + 1, len(tasks))\n",
        "\n",
        "      # choose tuner\n",
        "      tuner = \"xgb\"\n",
        "      tuner_obj = XGBTuner(task, loss_type=\"reg\")\n",
        "      tuner_obj.tune(\n",
        "            n_trial=min(tuning_option[\"trials\"], len(task.config_space)),\n",
        "            early_stopping=tuning_option[\"early_stopping\"],\n",
        "            measure_option=tuning_option[\"measure_option\"],\n",
        "            callbacks=[\n",
        "                autotvm.callback.progress_bar(tuning_option[\"trials\"],prefix = prefix),\n",
        "                autotvm.callback.log_to_file(tuning_option[\"tuning_records\"]),\n",
        "            ],\n",
        "        )\n",
        "  with autotvm.apply_history_best(tuning_option[\"tuning_records\"]):\n",
        "    with tvm.transform.PassContext(opt_level=3, config={}):\n",
        "        lib = relay.build(mod, target=target, params=params)\n",
        "\n",
        "  dev = tvm.device(str(target), 0)\n",
        "  module_optim = graph_executor.GraphModule(lib[\"default\"](dev))\n",
        "  return module_optim"
      ],
      "metadata": {
        "id": "klPD3gB7f-C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Autotune\n",
        "test(normal = False,jit_autotune = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mZxDoKdchfQ",
        "outputId": "c14529b9-fe68-4fa7-8de0-b070f230f9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful to build network!\n",
            "load pretrained model successful!\n",
            "Relay Autotune Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-255e429946bd>:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lprnet.load_state_dict(torch.load(args.pretrained_model, map_location=device))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "WARNING:autotvm:One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Task  1/13]  Current/Best:   10.09/  15.53 GFLOPS | Progress: (20/20) | 69.75 s Done.\n",
            "[Task  2/13]  Current/Best:    4.14/  11.94 GFLOPS | Progress: (20/20) | 60.58 s Done.\n",
            "[Task  3/13]  Current/Best:   12.92/  12.92 GFLOPS | Progress: (20/20) | 80.27 s Done.\n",
            "[Task  4/13]  Current/Best:    3.43/  16.02 GFLOPS | Progress: (20/20) | 61.47 s Done.\n",
            "[Task  5/13]  Current/Best:    9.81/  12.75 GFLOPS | Progress: (20/20) | 111.07 s Done.\n",
            "[Task  6/13]  Current/Best:    9.81/  15.70 GFLOPS | Progress: (20/20) | 51.82 s Done.\n",
            "[Task  7/13]  Current/Best:   10.76/  14.63 GFLOPS | Progress: (20/20) | 95.38 s Done.\n",
            "[Task  8/13]  Current/Best:    9.40/  19.32 GFLOPS | Progress: (20/20) | 96.74 s Done.\n",
            "[Task  9/13]  Current/Best:   13.59/  16.48 GFLOPS | Progress: (20/20) | 131.45 s Done.\n",
            "[Task 10/13]  Current/Best:    6.38/  18.92 GFLOPS | Progress: (20/20) | 140.17 s Done.\n",
            "[Task 11/13]  Current/Best:   17.46/  18.20 GFLOPS | Progress: (20/20) | 141.79 s Done.\n",
            "[Task 12/13]  Current/Best:    0.00/  10.71 GFLOPS | Progress: (20/20) | 207.74 s Done.\n",
            "[Task 13/13]  Current/Best:    4.09/  13.07 GFLOPS | Progress: (20/20) | 56.06 s Done.\n",
            "[Info] Test Accuracy: 0.9 [900:58:42:1000]\n",
            "[Info] Test Speed: 0.03762759494781494s 1/1000]\n",
            "Model Size: 1.7050743103027344 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "JIT Compilation Optimization"
      ],
      "metadata": {
        "id": "vIL0hSGs0lV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(normal = False, jit_compile=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgITS1shxh1L",
        "outputId": "4a6ae8b2-86b6-4f5d-8931-58a656b27450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful to build network!\n",
            "load pretrained model successful!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-56-c946ab66bb01>:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lprnet.load_state_dict(torch.load(args.pretrained_model, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JIT Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Test Accuracy: 0.899 [899:60:41:1000]\n",
            "[Info] Test Speed: 0.24823261880874634s 1/1000]\n",
            "Model Size: 0.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahead of Time Compilation Optimization"
      ],
      "metadata": {
        "id": "Nrs2YH3R0rUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(normal = False, torch_compile=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E4P98jGxp04",
        "outputId": "0a6a5346-f6f8-4731-bd9b-cca90b754f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful to build network!\n",
            "load pretrained model successful!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-56-c946ab66bb01>:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lprnet.load_state_dict(torch.load(args.pretrained_model, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch Model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/onnxscript/converter.py:820: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
            "  param_schemas = callee.param_schemas()\n",
            "/usr/local/lib/python3.10/dist-packages/onnxscript/converter.py:820: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
            "  param_schemas = callee.param_schemas()\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Test Accuracy: 0.898 [898:61:41:1000]\n",
            "[Info] Test Speed: 0.09941262602806092s 1/1000]\n",
            "Model Size: 1.1237754821777344 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorRT Optimization\n"
      ],
      "metadata": {
        "id": "6cHAACF500lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(normal = False, tensorrt_compile=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EO3YJeZ3g_-",
        "outputId": "94bb4f72-2fb7-4cd9-f591-4aae068caf69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:<ipython-input-6-f1d13591721c>:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lprnet.load_state_dict(torch.load(args.pretrained_model, map_location=device))\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful to build network!\n",
            "load pretrained model successful!\n",
            "TensorRT Model\n",
            "[Info] Test Accuracy: 0.9 [900:58:42:1000]\n",
            "[Info] Test Speed: 0.025034095525741578s 1/1000]\n",
            "Model Size: 1.7050743103027344 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining Weight Quantization and Autotuning"
      ],
      "metadata": {
        "id": "QocJkydO7ABD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(normal=False, quant_tensorrt_compile_flag=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hubd4CUzoMXs",
        "outputId": "296424c1-46ac-48fa-dc2c-5e2843ae5fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:<ipython-input-17-e1aa8aaca8b1>:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lprnet.load_state_dict(torch.load(args.pretrained_model, map_location=device))\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful to build network!\n",
            "load pretrained model successful!\n",
            "Weight Quantized Model\n",
            "Quant TensorRT Model\n",
            "[Info] Test Accuracy: 0.9 [900:62:38:1000]\n",
            "[Info] Test Speed: 0.012115023374557495s 1/1000]\n",
            "Model Size: 0.2580413818359375 MB\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}